{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9V-Rn_atzVm8"
   },
   "source": [
    "#ELEN 6885 Reinforcement Learning Coding Assignment (Part 4)#\n",
    "There are a lot of official and unofficial tutorials about Tensorflow, and there are also many open-source projects written in Tensorflow. You can refer to those resources according to your interest. In this part of homework 4, only knowledge of Deep Reinforcement Learning and basic programming skills will be needed.\n",
    "\n",
    "Please put your code into the block marked by\\\n",
    "\\############################\\\n",
    "\\# YOUR CODE STARTS HERE\\\n",
    "\\# YOUR CODE ENDS HERE\\\n",
    "\\############################\\\n",
    "Normally you don't need to edit anything outside of the block. If you do want to edit something, please use a similar manner to mark you edits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jcP9HjJGlP5j"
   },
   "source": [
    "Blank 1: you are supposed to complete building the target net.\n",
    "\n",
    "Blank 2: you are supposed to complete the calculation of the q target.\n",
    "\n",
    "Blank 3: you are supposed to complete the training process. More specifically, you will need to reset the environment after each episode, calculate episode length, calculate and take action, observe and store transition into memory.\n",
    "\n",
    "Blank 4: you are supposed to let the trained agent play the game 100 times and print out how long can the agent play for each time. Codes will be similar to those of blank 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DESXLxAP9fLI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# DQN\n",
    "class DQN:\n",
    "  def __init__(\n",
    "      self,\n",
    "      actions_num,\n",
    "      state_size,\n",
    "      learning_rate = 0.001,\n",
    "      gamma = 0.99,\n",
    "      epsilon_min = 0.05,\n",
    "      epsilon_start = 0.9,\n",
    "      replace_target_iter = 300,\n",
    "      memory_size = 500,\n",
    "      batch_size = 2,\n",
    "      epsilon_increment = None,\n",
    "  ):\n",
    "      self.actions_num = actions_num\n",
    "      self.state_size = state_size\n",
    "      self.lr = learning_rate\n",
    "      self.gamma = gamma\n",
    "      self.epsilon_min = epsilon_min\n",
    "      self.replace_target_iter = replace_target_iter\n",
    "      self.memory_size = memory_size\n",
    "      self.batch_size = batch_size\n",
    "      self.epsilon_increment = epsilon_increment\n",
    "      self.epsilon = epsilon_start if epsilon_increment is not None else self.epsilon_min\n",
    "      self.save_model_path = './weights/DQN_model.ckpt'\n",
    "      self.memory_counter = 0\n",
    "\n",
    "      # learned steps counter\n",
    "      self.steps_counter = 0\n",
    "\n",
    "      # initialize memory [s, a, r, s_, done]\n",
    "      self.memory = np.zeros((self.memory_size, state_size * 2 + 3))\n",
    "\n",
    "      # build target_net and q_net\n",
    "      self.build_net()\n",
    "      t_params = tf.get_collection('target_net_params')\n",
    "      q_params = tf.get_collection('q_net_params')\n",
    "      self.replace_target = [tf.assign(t, q) for t, q in zip(t_params, q_params)]\n",
    "\n",
    "      # gpu setting\n",
    "      config = tf.ConfigProto(log_device_placement=False, allow_soft_placement=True)\n",
    "      config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "      self.sess = tf.Session(config=config)\n",
    "\n",
    "      self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "  def build_net(self):\n",
    "    # build q_net\n",
    "    self.state = tf.placeholder(tf.float32, [None, self.state_size], name='state')\n",
    "    self.q_target = tf.placeholder(tf.float32, [None, self.actions_num], name='Q_target')\n",
    "    with tf.variable_scope('q_net'):\n",
    "      # c_names(collections_names) are the collections to store variables\n",
    "      c_names, neurons_layer_1, w_initializer, b_initializer = \\\n",
    "        ['q_net_params', tf.GraphKeys.GLOBAL_VARIABLES], 100, \\\n",
    "        tf.random_normal_initializer(0., 0.3), tf.constant_initializer(0.1)\n",
    "\n",
    "      # layer 1\n",
    "      with tf.variable_scope('layer_1'):\n",
    "        w_layer_1 = tf.get_variable('w_layer_1', [self.state_size, neurons_layer_1], initializer=w_initializer, collections=c_names)\n",
    "        b_layer_1 = tf.get_variable('b_layer_1', [1, neurons_layer_1], initializer=b_initializer, collections=c_names)\n",
    "        layer_1 = tf.nn.relu(tf.matmul(self.state, w_layer_1) + b_layer_1)\n",
    "\n",
    "      # layer 2\n",
    "      with tf.variable_scope('layer_2'):\n",
    "        w_layer_2 = tf.get_variable('w_layer_2', [neurons_layer_1, self.actions_num], initializer=w_initializer, collections=c_names)\n",
    "        b_layer_2 = tf.get_variable('b_layer_2', [1, self.actions_num], initializer=b_initializer, collections=c_names)\n",
    "        self.q_value = tf.matmul(layer_1, w_layer_2) + b_layer_2\n",
    "\n",
    "    with tf.variable_scope('loss'):\n",
    "      self.loss = tf.reduce_mean(tf.squared_difference(self.q_target, self.q_value))\n",
    "    with tf.variable_scope('train'):\n",
    "      self._train_op = tf.train.AdamOptimizer(self.lr).minimize(self.loss)\n",
    "\n",
    "    # build target_net\n",
    "    self.state_t = tf.placeholder(tf.float32, [None, self.state_size], name='state_t')    # input\n",
    "    with tf.variable_scope('target_net'):\n",
    "      # c_names(collections_names) are the collections to store variables\n",
    "      c_names = ['target_net_params', tf.GraphKeys.GLOBAL_VARIABLES]\n",
    "\n",
    "      # layer 1\n",
    "      with tf.variable_scope('layer_1'):\n",
    "        w_layer_1 = tf.get_variable('w_layer_1', [self.state_size, neurons_layer_1], initializer=w_initializer, collections=c_names)\n",
    "        b_layer_1 = tf.get_variable('b_layer_1', [1, neurons_layer_1], initializer=b_initializer, collections=c_names)\n",
    "        layer_1 = tf.nn.relu(tf.matmul(self.state_t, w_layer_1) + b_layer_1)\n",
    "\n",
    "      # layer 2\n",
    "\n",
    "      ############################\n",
    "      # YOUR CODE STARTS HERE\n",
    "      # \"self.q_next\" should be defined by you in the first blank where you are required to complete building the target net.\n",
    "      #Note that q_next (Q(s’, a’)) is the q value given by the target network while R + Q(s’, a’) is the q_target. \n",
    "      # YOUR CODE ENDS HERE\n",
    "        \n",
    "      with tf.variable_scope('layer_2'):\n",
    "        w_layer_2 = tf.get_variable('w_layer_2', [neurons_layer_1, self.actions_num], initializer=w_initializer, collections=c_names)\n",
    "        b_layer_2 = tf.get_variable('b_layer_2', [1, self.actions_num], initializer=b_initializer, collections=c_names)\n",
    "        self.q_next = tf.matmul(layer_1, w_layer_2) + b_layer_2\n",
    "\n",
    "\n",
    "      ############################\n",
    "     \n",
    "  def store_transition(self, s, a, r, s_, done):\n",
    "    s=s.reshape(-1)\n",
    "    s_=s_.reshape(-1)\n",
    "    transition = np.hstack((s, [a, r], s_, done))\n",
    "\n",
    "    # replace the old memory with new observations\n",
    "    index = self.memory_counter % self.memory_size\n",
    "    self.memory[index, :] = transition\n",
    "\n",
    "    self.memory_counter += 1\n",
    "\n",
    "  def choose_action(self, observation):\n",
    "    # to have batch dimension when fed into tf placeholder\n",
    "    observation = observation[np.newaxis, :]\n",
    "    # epsilon-greedy\n",
    "    if np.random.uniform() > self.epsilon:\n",
    "      action_values = self.sess.run(self.q_value, feed_dict={self.state: observation})\n",
    "      action = np.argmax(action_values)\n",
    "    else:\n",
    "      action = np.random.randint(0, self.actions_num)\n",
    "    return action\n",
    "\n",
    "  def learn(self):\n",
    "    # replace target parameters every once a while\n",
    "    if self.steps_counter % self.replace_target_iter == 0:\n",
    "      self.sess.run(self.replace_target)\n",
    "\n",
    "    # sample a batch from the memory\n",
    "    if self.memory_counter > self.memory_size:\n",
    "      sample_index = np.random.choice(self.memory_size, size=self.batch_size)\n",
    "    else:\n",
    "      sample_index = np.random.choice(self.memory_counter, size=self.batch_size)\n",
    "    batch_memory = self.memory[sample_index, :]\n",
    "\n",
    "    q_next, q_value = self.sess.run(\n",
    "      [self.q_next, self.q_value],\n",
    "      feed_dict={\n",
    "        self.state_t: batch_memory[:, -self.state_size-1:-1],  # fixed params\n",
    "        self.state: batch_memory[:, :self.state_size],  # newest params\n",
    "      })\n",
    "    #print(q_next, q_value)\n",
    "    # calculate q_target\n",
    "    q_target = q_value.copy()\n",
    "    #print(q_target)\n",
    "    # only change the action-values of this batch, because we only calculate loss on the batch observations\n",
    "    batch_index = np.arange(self.batch_size, dtype=np.int32)\n",
    "    act_index = batch_memory[:, self.state_size].astype(int)\n",
    "    reward = batch_memory[:, self.state_size + 1]\n",
    "    done = batch_memory[:, -1]\n",
    "    #print(batch_index,act_index, reward, done)\n",
    "    ############################\n",
    "    # YOUR CODE STARTS HERE\n",
    "    #complete the calculation of q_target. The action value of the terminal state should be 0.\n",
    "    for ind in batch_index:\n",
    "      act_ind = act_index[ind]\n",
    "      r = reward[ind]\n",
    "      done_flag = done[ind]\n",
    "      if done_flag:\n",
    "          q_target[ind][act_ind] = r\n",
    "      else:\n",
    "          q_target[ind][act_ind] = r + self.gamma * np.max(q_next[ind])\n",
    "    # YOUR CODE ENDS HERE\n",
    "    ############################\n",
    "    \n",
    "    # train q_net\n",
    "    _, self.cost = self.sess.run([self._train_op, self.loss],\n",
    "                                  feed_dict={self.state: batch_memory[:, :self.state_size],\n",
    "                                            self.q_target: q_target})\n",
    "    # change epsilon\n",
    "    self.epsilon = self.epsilon - self.epsilon_increment if self.epsilon > self.epsilon_min else self.epsilon_min\n",
    "    self.steps_counter += 1\n",
    "\n",
    "  def store(self):\n",
    "    saver = tf.train.Saver() \n",
    "    saver.save(self.sess, self.save_model_path)\n",
    "  \n",
    "  def restore(self):\n",
    "    saver = tf.train.Saver() \n",
    "    saver.restore(self.sess, self.save_model_path)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "R_Pan2x1XlxB",
    "outputId": "d39fe377-8359-4b65-92cf-57f61c948770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(2)\n",
      "Box(4,)\n",
      "(array([-0.0356235 ,  0.17791025,  0.01786908, -0.26963286]), 1.0, False, {})\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "# cart pole gym environment\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "env._max_episode_steps = 500\n",
    "# state and action space\n",
    "print(env.action_space)\n",
    "print(env.observation_space)\n",
    "# observation\n",
    "env.reset()\n",
    "# state, reward, done, info\n",
    "print(env.step(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UMOz0IC6cJqt"
   },
   "outputs": [],
   "source": [
    "# play the game and train the network\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "episode_length_set = []\n",
    "tf.reset_default_graph()\n",
    "total_time_steps = 100000\n",
    "\n",
    "RL = DQN(actions_num = 2, gamma = 0.99,\n",
    "         state_size = 4, epsilon_start = 1,\n",
    "         learning_rate = 1e-3, epsilon_min = 0.01,\n",
    "         replace_target_iter = 100, memory_size = 5000,\n",
    "         epsilon_increment = 0.00001,)\n",
    "\n",
    "new_state = env.reset()\n",
    "done = False\n",
    "episode_length_counter = 0\n",
    "for step in range(total_time_steps):\n",
    "  ############################\n",
    "  # YOUR CODE STARTS HERE\n",
    "    action = RL.choose_action(new_state)\n",
    "    state_next, reward, done, info = env.step(action)\n",
    "    reward = reward if not done else -reward\n",
    "    #state_next = np.reshape(state_next, [1, observation_space])\n",
    "    RL.store_transition(new_state, action, reward, state_next, done)\n",
    "    new_state = state_next\n",
    "    if done:\n",
    "        episode_length_set.append(episode_length_counter)\n",
    "        new_state = env.reset()\n",
    "        done=False\n",
    "        episode_length_counter =0\n",
    "          \n",
    "  # YOUR CODE ENDS HERE\n",
    "  ############################\n",
    "  \n",
    "    if step > 200: #To make sure we have some amount of samples in the memory when we call RL.learn.\n",
    "      RL.learn()\n",
    "    episode_length_counter += 1\n",
    "    if episode_length_counter == 500:\n",
    "      RL.store()\n",
    "#RL.store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "LCxAuNQegi2Q",
    "outputId": "889acc80-b4c4-4aa0-c9bd-567437eb3b3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f172b62c048>]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXwU5f0H8M+XBBLuMxxyBRAPPBBI\nBYV64YHoT6za1qOKVItW29rqryWiv1ZbrVqtVrwtqHjfChIQkUME5Qj3TQIESIAkBAghkHOf3x87\ns5ndnZ2d2eyZ/bxfL8zszOzMs+Pud5/9Ps88jyilQERETV+zWBeAiIiigwGfiChJMOATESUJBnwi\noiTBgE9ElCRSY10AAOjSpYvKzMyMdTGIiBLKqlWrDiqlMuzuHxcBPzMzE7m5ubEuBhFRQhGR3U72\nZ0qHiChJMOATESUJBnwioiTBgE9ElCQY8ImIkoStgC8iBSKyQUTWikiutq6TiMwTkTztb0dtvYjI\nFBHJF5H1IjI0ki+AiIjscVLDv1gpdY5SKkt7nA1gvlJqIID52mMAuBLAQO3fRACvhKuwREQUusb0\nwx8H4CJteTqARQAmaevfVu5xl5eJSAcR6aGU2t+YghIRxbPK6jp8s/kAhvXphPdW7Mbp3dth+a4y\nVNW6sKGoHGPO6I41ew9j4gUDsPfQcXRvl44NReW45LSuGNy7Q1TKaDfgKwDfiIgC8JpS6nUA3QxB\n/ACAbtpyTwB7Dc8t1NZ5BXwRmQj3LwD06dMntNITEcWJR7/ahI9zCwNuf7EkHwCwNL/Ma31G27S4\nC/ijlFJFItIVwDwR2WrcqJRS2peBbdqXxusAkJWVxVlYiCihHaqscfycVi1S8KsRfSNQGnO2cvhK\nqSLtbwmALwCcC6BYRHoAgPa3RNu9CEBvw9N7aeuIiJqMT1cV4rvtpZ7Hac1THB+jmUg4ixT8fMF2\nEJHWItJWXwZwOYCNAGYCGK/tNh7ADG15JoDbtN46IwCUM39PRE3N/36yDuPfWOF5nJ7qPOBHN9zb\nS+l0A/CFuL+JUgG8r5T6WkRWAvhYRO4AsBvAL7T9ZwMYCyAfwHEAE8JeaiKiONOyhfPbmqJcwQ8e\n8JVSOwEMNllfBmC0yXoF4N6wlI6IKEGEVMOPt5QOEREFl9LMefAO4SmNwoBPRBQjrOETESWQz1cX\nIjM7B6UV1Y6fyxo+EVEC+XCl+z7THQcrQ3g2a/hEREmBNXwioiQR7W6ZDPhERI3RiIFh4u5OWyIi\nioxo32nLgE9E1Bg2o/aNP+ntt47dMomIEonNlM7PhvT0W8ccPhFRAllRcMi9oKwjv1ltnjl8IqIm\nyKwLJmv4RERNkFlwZw2fiKhJ8g/u7KVDRNQk+ef4mdIhIkoS7JZJRNQkmfXSiW4JGPCJiGJEOFom\nEVHiCWVIHebwiYiSBHP4RERJIto5/NTono6IKLF9vXE/Nu07GpZjRTulw4BPROTA3e+uDtuxeKct\nEVGS4J22RERJgo22RERJgt0yiYiSBHP4RERJgjl8IqIkwRo+EVGyYA6fiCjxrC8sd/ycuB0tU0RS\nRGSNiMzSHvcTkeUiki8iH4lIC219mvY4X9ueGZmiExEljoHd2viti+fRMu8DsMXw+CkAzymlTgZw\nGMAd2vo7ABzW1j+n7UdElNTapTfHw1ed7rWuWZRzLLZOJyK9AFwFYKr2WABcAuBTbZfpAK7Vlsdp\nj6FtHy3RvruAiChOPHrNGfj8nvNNt8VrDf8/AP4CwKU97gzgiFKqTntcCKCnttwTwF4A0LaXa/t7\nEZGJIpIrIrmlpaUhFp+IKL6NPLkzhvbpaLot7m68EpGrAZQopVaF88RKqdeVUllKqayMjIxwHpqI\nKI4EjurRTn7YGS1zJIBrRGQsgHQA7QA8D6CDiKRqtfheAIq0/YsA9AZQKCKpANoDKAt7yYmIEoBV\nT5y466WjlHpQKdVLKZUJ4EYAC5RStwBYCOAGbbfxAGZoyzO1x9C2L1BKhTL7FxFRwksxRPWeHVp6\nbUukO20nAbhfRPLhztFP09ZPA9BZW38/gOzGFZGIKHEZ76Ydc2b3gNuiwdEEKEqpRQAWacs7AZxr\nsk8VgJ+HoWxERAnPGNN9c/Zx12hLREShs6rFczx8IqImJMWiZTaRcvhERBSEVSWeo2USETUh1imd\nKBYEDPhERBFlFfBr66PbY50Bn4goglIsAn5VbX0US8KAT0QUURJHUTaOikJEFDmZ2Tn444dron5e\nq5SOAlM6REQR8eXafVE/p9V4OdEedIYBn4jIwsFj1ThWXRd8xwAsa/gM+ERE8SPrsW9x8TOLQn4+\nUzpERAmktKI65OcypUNElCSshlaINgZ8IqIIshogLdoThTDgExHFClM6RETJgY22REQUEQz4RESa\n8hO1yMzOwWerCqNyPvbSISKKkb2HjgMApi7ZFZXzsdGWiChGoj0+vYpyFZ8Bn4jIpnpXtOvk4cWA\nT0RkU1ll6HfcmmFKh4goTqWlpNjed2DXNnjvzuGW+0S70TY1uqcjIop/gXLrdvvN3zmqH35zQX90\na5dufR7HJWscBnwiIo3AutXWbo384asHBdzWrV0aio9WOztgmDClQ0RJZ/H2UqwsOOT4eeEIz4N7\ndQjr8ZxgDZ+Iks5tb6wAAPz5ilNx78Une9br3TK3HqiI2Lmj3fXTiDV8IkpaT8/dFnBb8dEqv3Xh\n6DdvTBvxTlsiohgx1r6P19T7bQ9HfG5miLocPI2IKILW7j1iaz+zeUvCUSM31vCDNRKHGwM+ESWV\na19aams/s2BsVSO3PbGVYb/fXNDf5pPCI2jAF5F0EVkhIutEZJOIPKqt7yciy0UkX0Q+EpEW2vo0\n7XG+tj0zsi+BiCj8fBtXq+v8UzxGaan2bsrKaJMGAJg2PgvXDD4ppLKFyk4NvxrAJUqpwQDOATBG\nREYAeArAc0qpkwEcBnCHtv8dAA5r65/T9iMiSijNfKrsZ/3tG8skfqrNKn72lafhnz87C5ec1rUx\nxQtJ0ICv3I5pD5tr/xSASwB8qq2fDuBabXmc9hja9tFiNakjEVGcMKZxfON3Tb3Lsok1JUXQp1Or\noOdIb56Cm4f3sZzrNlJs9cMXkRQAqwCcDOAlADsAHFFK1Wm7FALoqS33BLAXAJRSdSJSDqAzgINh\nLDcRUUSZ5vAtIn6KCBY8cGHUb6ZywlajrVKqXil1DoBeAM4FcFpjTywiE0UkV0RyS0tLG3s4IqKw\nMmugtWy0bSZITWmG5inx2xfGUcmUUkcALARwHoAOIqL/QugFoEhbLgLQGwC07e0BlJkc63WlVJZS\nKisjIyPE4hMRhY9vlsVuF07Afg4/luz00skQkQ7acksAlwHYAnfgv0HbbTyAGdryTO0xtO0LVLSn\ndSEiMpi5bp+t/Ywhe9G2Ur8unFaRrFkCNFXayeH3ADBdy+M3A/CxUmqWiGwG8KGIPAZgDYBp2v7T\nALwjIvkADgG4MQLlJiKypbK6Dn/4YI3j560v9K/dWzbaJkANP2jAV0qtBzDEZP1OuPP5vuurAPw8\nLKUjImqkuhCnJSyt8J/dyipZ0SRSOkREycIYzqvrXP7brVI6DPhERInJ5bDpMSUBcvgM+ETUpD31\n9Vbb+xpjvMu/gm8pEXL4DPhE1KS9v3yP5fbPVxd6lo397M1q+FaV/tQUBnwiorj2v5+s8yx71fDN\nAr7laJkM+EREcU0P1EeO12DOhv2e9Wadeyxr+AmQ0uGctkSU1PSK+V3vrMLyXQ0TmztttGUvHSKi\nOKcPklZQVum13mVSxbe88YopHSKiOKfF6bp673BultKxqvWz0ZaIKM7pYbq23rsfptNeOmy0JSKK\nc3qgrncFr+FzaAUiogSmV8xrfSK8WXAPFO7P698ZD449PcwlCz/20iGipKbX8Ot8UjpmlflAFfwP\nJo4Id7EigjV8IkpqeiLGN4VTbxLdnXbVjDcM+ESU3AKk3s2C+8e5eyNcmMhiwCeipBaoqdWsMv/m\n0oJIFiXiGPCJKKlJgO6Uvr12mgIGfCJKaoG6z1vl63t1bBmh0kQWAz4RJTUnKZ1Ex4BPRAmn/EQt\nxr24BLsOViK/5Bi2F1eEfKxAd8ha3WSVqF8G7IdPRAnn283FWFdYjinz8/DFmiIAQMGTV4V0rIA5\n/ESN6hZYwyeihKNPJ2jVsLpwawlqTCYi9xU4hx/4OVa1/3jGGj4RJRw9SAdqWM0tOIQJb63EHaP6\nBT9WgPWWKZ2gR41PrOETUcLR8+6BYnJZZQ0AYHfZ8aDHClTDt/r1kKAVfAZ8Iko8dlI6dkmAOr7v\n+PhNAQM+ESUcz5DGYahqB6rhH6upC/gcq8nM4xkDPhElnMlfbAAQOM+ur15feCTosULph5+oKR02\n2hJRwjmk5ejNUjpv/1iAT1cVAgAOH68JeqxA3TKtJGi8Z8AnosRljPdVtfWYtmQXnp67zbPOnZ+3\nDs9FR05gf/kJR+dlDZ+IKMqM3TJfWbQDz8/PC+k4q3cHT/14S8yIzxw+EcXEtgMVmLV+X6OOYQz4\nJ2rr/Xewma1xmtUx1vDHn9fX2ZNjiDV8IoqJK/6zGABw9dknhXwMYw4/t+CQ33a784o7zeIb6/ft\nWzZ3+OzYCVrDF5HeIrJQRDaLyCYRuU9b30lE5olInva3o7ZeRGSKiOSLyHoRGRrpF0FEycmYw1+9\nxz8tE6m+9MbeQVU2hm+IF3ZSOnUAHlBKDQIwAsC9IjIIQDaA+UqpgQDma48B4EoAA7V/EwG8EvZS\nExEBcAW58arO5o1ZTlM6p3Rr61muMkslxamgAV8ptV8ptVpbrgCwBUBPAOMATNd2mw7gWm15HIC3\nldsyAB1EpEfYS05ESWNjUTkWbi3xWx++ES2dRfwbhvXCrSPcufsmFfCNRCQTwBAAywF0U0rt1zYd\nANBNW+4JwDjTb6G2zvdYE0UkV0RyS0tLHRabiJLJ1S8swYS3Vvqt31FyLCzHD6ErPob17QgAqKpt\nWikdAICItAHwGYA/KqWOGrcpd0LL0VetUup1pVSWUiorIyPDyVOJiAAAR6sCD3/gxF3vrHK0vwJw\nVq/2AIDRp3cNSxmiwVYvHRFpDnewf08p9bm2ulhEeiil9mspG/33VhGA3oan99LWERE1DQoYkNEG\n2x4bg7TUlFiXxjY7vXQEwDQAW5RSzxo2zQQwXlseD2CGYf1tWm+dEQDKDakfIkpy+SUVmLe52G/9\njzvKsGbPYc/jmjoXauvjM12iD56WSMEesFfDHwngVgAbRGSttm4ygCcBfCwidwDYDeAX2rbZAMYC\nyAdwHMCEsJaYiBLapc8uNl1/03+XAWiYqvCMv32N2nqVUDc2xbugAV8ptQSBm7BHm+yvANzbyHIR\nUYKpqXOhmQCpKY27gb/8RC0GP/qN5/H0H3c3tmhhl6hj6XBoBSIKi1MenoPrXvmh0ce54jnzXwDx\nJEHjPQM+EYXP+sLyRh/jwNGqMJQksljDJyKiuMaAT0TkEKc4JCIK0dTvd8a6CJa6tk2LdRHCggGf\niGLusZwtsS6CpavO9h4OjDl8IqIkkaDxngGfiMixBK3iM+ATJZG6ehfyiitiXYyEl5jhngGfKKk8\nOWcrLntuMfaUHY91USgGGPCJ4sTuskpkZufgq3WNm9jbSu5u9+BkpceqI3aOZJCgGR0GfKJ4sXmf\ne5qJnPWRG1y2YaKP+IlYlz77XayL4JhK0IjPgE+URPR4H0q8qqlzoeBgZVjLAwD5YZq1KpJ8r9dP\nT0nMSZsY8ImSiGhV/FDqp5O/2ICLnlmE8uO14S1UgvllVm8MyGgT62KEhAGfKIk0poa/NP8gAKCy\nJjzTCiaqRB1WAWDAJ0oqeg4/UXPQ0dY2LRXZV54W62KEDQM+URJiuLfn7osG4O4LB8S6GGHDgE8U\nJxoThH//wRq8uXRX0P0k4OR1ZEZMLlci/zhiwCeKM2ZBJpiv1u3Do19ttnFw959EDlrR1NS+IO1M\nYk5ETYSn0TaMSZ1j1XVYuetQ2I4XT0xr+NEvRtiwhk+URKQh4ofN/R+txYS3VnoeL95e6lleuK0E\nczcdCN/Joqxp1e8Z8ImSip6iCCXeG9NAVbX1uP6VH7Bmz2Hs8rkZa9b6hqEhJry5Ene9syqUoppa\nu/cI9h7iOEChYkqHKIlImHL4W/Yfxardh/G3mZv8tqWmmNcjXS6F/Y2coPzal5Y26vlONTPJ6SRy\n+wdr+ERJxBPwQ6jjG2NfdZ0LALC+sBx7fGrc7y/fY/r8V77bgZFPLnB8XjNnnNQuLMcJJpQG9HjG\ngE+URDwpnUbWUqtq6z3LevAPZnkYG3Zbt4hucsJ4oxrvtCWihNBQw3dmR+kx7C9vSMfYDfJG6anh\nCzfRCrrSxLrpMOATJSFjjfXV73YgMzsH9a7Akezf32zzehws4JsN3ZDePMVhKQOrqnX+hROKJpbR\nYcAnSiZmo2U+O287AKC2PnAQNcZvBfdUiVbMvjtahjHgH62KzoidTayCz4BPwdXUuXC4sibWxYh7\nSilkZufg5UX5IT7f/XfOxgOY/kNB+ApmYDr/icMIppQK2ph54GiVXwNtevPwhZu6+iildKJyluhh\nwKegfvvuKgz5x7xYFyPu6bXap+duQ02dC7e/uQKb9pWHdKwp8/PCWLIGVr10XDZbcpUKPuTAyCcX\noOjICa91zZqFL3xapZ/CyTSHn8AY8Cmo+VtLYl2EhGDMW2/efxSLtpVi8ucbwnoOl8v9K+K/i3eG\n9Hyz8fD14G8WQ6vr6lF+vNavV4/TOFhdV483lxY4e5KFA43sz29078WBR8M0HzwtcZM6QQO+iLwh\nIiUistGwrpOIzBORPO1vR229iMgUEckXkfUiMjSShaema/H20qjV4sJFL65SDbXlvEZM31dVW4/b\n31yBHaUNx6jRcudP+zSi2uXJ4RsDvrZsVsO/c3ouBv/9G691Sjmv+R6J41myLhvUPeC2xswQFo/s\n1PDfAjDGZ102gPlKqYEA5muPAeBKAAO1fxMBvBKeYlIyWbitBLe9sQKvfrcj1kVxxJgm0WPn8Zr6\nAHsDG4vKMWeD+YTlCu4ZphZtK8XjOVs86/WgnBJiqsFsKB19efrSAmRm53g1yH6fd9CkbMpxLTee\nv7ytMk1mm+L3lQQXNOArpRYD8L1jYhyA6drydADXGta/rdyWAeggIj3CVVhKDiXaz/XdZeGfMDuS\nvGvNwcPC1S8swW/fWx1wux4jjUFHD5yhpsPNZrzSl/+t9daprPb/kiqpqDLs7/zGrWg1sobCqj2i\niaXwQ87hd1NK6VWTAwC6acs9Aew17FeorfMjIhNFJFdEcktLS812IbJ0vKbO647PWPPtumiXWRdD\npRpq0XrQKT9R6+n/rjeA7iw9hszsHK/n7iw9hs9XF3oef7660JAW8k9R+Ja11uXf5XL1niNe+zu9\n8am6Ln7+P/lqakHdSqMbbZX7Xen461sp9bpSKksplZWRkdHYYlAUxFtj1aC/zsXFzywK+3GX7SzD\n5C+cN7Yag6DLQQrj7EfcOXLfwNNwBEFdvQuDH/0G2Z+5y6UP6rVom39l6fLnFuP+j9d5Ht//8Tpc\n/txir3OY5fD1Xw3BauNKKZh8J1gK5c7caDEbIE1nVvv/zU/7R7I4ERVqwC/WUzXaX70bRxGA3ob9\nemnrKM7Uu5Tjm1fiLN4DgNft/uFy4+vLAg4AZsUVYg0fMP8y1Vd9u6UYQ7Vusd9uKQbQEJznbS72\ne16dyZeNngpqCF/+++iBz+oGLP2ZTl9fotbwfVNnj15zBs7s2T6yBYqgUAP+TADjteXxAGYY1t+m\n9dYZAaDckPohBzYUlqMigncT/v2rTTj7kW+CpkS27D/qWbbbT7upcPqLxjsv7r1tY1E5yk8E/v/p\nu78y/BcAjlbVeW3Xg/OPO8scldFqeGQ9TWT8wmie4h8N7/9oLfJKKhydtzpKQyGEwrKG38TSPXa6\nZX4A4EcAp4pIoYjcAeBJAJeJSB6AS7XHADAbwE4A+QD+C+CeiJS6iautd+F/XlyCO6bnRuwcX651\nT1IRLODfa2hUDDXc55dUIDM7B1sPHA2+cxxx+v3mVcP3efLVLyzBja8vC/jceosavplQb2LSUxRm\nGSe950+NIf2SYnKedYXleO07Z/cBVAf51RBLVkE9XKOLxougY4wqpW4KsGm0yb4KwL2NLVSy02vS\naw0NZfEg1Br+7A3uKe5mrduP07pHZxzzcHAphWZObq4PktIx/loyO5dvXt3qatuJ9+4hELx31B+a\n/b/Ug3uwlE4o4ruGH3jbhac2rfZF3mkbh6JZmwh6LsOHIdRyRWLi7GhwKeDnr/6A7M/W29rfq9HW\n4cV658fdftfH6hh2+uG7u096H8Mq4OvbjA2swYZQsMt3GsT4Evg1dmuX7t6jiaR2GPANdpdVojiM\nt2yHKhoBP5Q3cMgBP0zT6ukWbivBSwtDG6DMCQWFlQWH8eHKvcF3hm9Kx7gc/IU/lrMFW/c35MWV\nT43fl507XRX8r7lVikKv4RtTOuEa/uapr7eG50ARYO/XUuTLEQ0M+AYXPr0Iw/85P9bFMM3nRkqw\nMxmL4lsrdI+PsivoXZR6cNp1sBKZ2TnYdsC6wU8/TaDLMOHNlXh6rvnQAgfKq/DZqkJtvxX400dr\nLc9lxe7NQsVH3ef0nhWpwaZ99toufPu/W53dLLcOALMNd+7e9c4q9J8823sH7Wl/tLguLqXww46D\nWLv3SJMbPMyMVaOtr0S/HJzEPA55AmsE31z6oYMFa1eAIAYALy3Ix5QF+WidlopfZPVGMHM2unP5\nX64twqQxpzkprm03T12GnaWVGHNmdyzU+qg/98tzQjrWQzb74o9/YwW2HqjA+78Z7llnvG5Xv7DE\n1nF80ydWvwyaifl2Y01a78LpfY4GLpfyavzVD1fvUrjtjRW2ytwUJHoQd4IBPw6pKLRvNQyiZT/g\n68v3fbgGNXUudG2bBgA4Xl1n+tzQy+b914m9PhNqN4bekymYkopqAMDN/13uWffGkl2Oz2d8vWbp\nGKNmInh5kf9YQ3Z/bQHuX5JmjdLxPO5NJDip4Sc6pnTiUDT7uwf7bBuzDHqxZqzd56mtW9m0rxz/\nnL0l4jWoA4abr2q1NEw0r6HZ7E9mg44F45ulsWrkbtZMTNNahYdPmOzdwGxcHl/JFvDtSLQOB4Ew\n4MdQoD7w0QxWwdoLzAbZsuvG15bh9cU7cdxnMK5wv7yHv9zoty7cMWvi24HviQjX62nmU8W3bLQN\n8RzGU/gGdv3/bzTbkOKBk3saEv23AAN+jBQcrMRp//c1Psn17wHi9ANXcLASj8zc5Gj8Fv2NG+w5\n9V4B31GxPF9codbw822OJW8+LEF4g9Y3JkMY6MyGMgiFbwOp1WErqkJLo3nV8ANcIyfvo6bAydsz\n0a8MA36MbC9291SZu8k/NeI0Vl30zCK89UMBtgbp/WJk1R/byPjZD9cvDxF3UNFv8Kmpc5kG6NU2\nbzwzK9U1Ly71LJefqPW6mejrjfv9pt+zy1huXSRSIO4cfuDjHgpxjmGvHH69woy1/kNdhesLLJZO\n7dbW9hy6zOFTTHlqxhE9S+Bb7I0CdTW0dQbRz+H/zPs+WouBD81BaUU1Tnl4TsDp79btPYLntHHa\n7ZRRt8fQeDv40W8w8KE5nsd3v7saP3tpqdf+hytrbDX4/ubtXAx8aI5nXJyPV+71zELlhFnA9n0d\nVtc7lHMC3u+psspq3PdhQ/dM/Xyh/nqIJ+5JWuzt6+Reg0T/amDAjxGr/s2BgrDLpcJem2xMDX+b\n9ivliyC9WXyL7HIpfLXO/ZzCw+4ga1bTBIBxLy3F89qE3kopfLTSfxRLJ5dET1foPWt0Fzy9ED/9\n18Kgz9fn973mRXdXy7/YvAtXV3K0CvUuZdrQGyinHi77y094/aL0HZBND/RTl4Q2X244pIbpTi9H\nl443XjVdSils2lce62JY0oOS73vsuld+wADfG2kM3lu+Gwu3OZtw3Cpfu7Go3CvIV1bXe90iv2yn\neyK0dXuPmI4T42kn8Pm0vGaYgNszq1OQn9VKKSzaXopJn/n3jXfyWQyUrrBTqzW+b3aXhdb987vt\npRgweTauf/UHv23e7SX2a6h2jX3+e1Qaply87mX/MgDed9pGm9NB4f4y5lTT9U4uHVM6Tdj7K/bg\nqilLsHi798QRkZzc40B5Fb4xydW7zwtc/8oPmPr9Tq91Ztbubchpu1zKL1i/t3wPJry50uf4/vsB\nxhy++bkWby/F1S8s8Zp8evwbKwJOOGI16qb1pXVvDPY5r3epgEF58fZSZGbn4NdvrTTd7nucUF01\nxd4NVFb0L7a9h/zbEHz/P4X7HXnY5kTisWy0bZHiLCRNDMNkJHbCfVP5Tki6gL9Zu83dd77USDRU\n/fubbZixtgjXv/IDJr6zyvOlUlFVi7/OaOhKuGr3YTxmmKjaWNM7eKwaj8zc5NdQOPyJ+Tj/yQVB\ny/DEnK3oP3l2wEC3vbgCz8zd5veFV2Ayn+weixy3ZYrK4trqL+vIcfc1CTRRRr0KPnH2gq3Wv272\nl59AnclUTdGcO9fqi834vzjYjVeRFMtGW7sNrYB7eIlA7zsnFTg7NfymktJpUnfabi+uQPmJWvwk\ns5Pt53j6Hof5Tb6y4BBeWOA9wNffZm5CVW09urZNt5ypydho++hXm/HVun0Y3s/7NZX65KADmabd\n8VnnciGlWYpnvf4W//0HawAAE0ZmonObNL/tdpnuH+RXBNBw09LOg5XYebAS5/TuYLqf0yn1zJz3\nxAKs/etlnsdXPv89fj0yE3/+tCEPf/4TkR1LySq2+Ka+YtUfPpY3XqWlpgTfSbN00iUB36cKwM+G\n9LQ18F1Tqb3b0aQCvj5vZ8GTVwXcxzNyI4Cn527FSwt34PqhvfDINYPCWpY9Jjnet3/cbeu5xtqJ\nHhCdfASVUnju2zxcMLCLZ53+Id5eXIGTM9r4vckbm8d0EsiMan2CS229y7Q2VR+mnLax9rpl/1Gv\nYA8A+yIwZaLRk3MCjxpp/PWhVOxSK7G88apVC/sBv3v79MA1eQU8du2ZePDK0+FSCkO0KSLNJMMA\ncbommdL5brv/xM46fYCq4qX6aMoAABKFSURBVKNVeGmheyySz1YXWt5m/umqwNsDadaIKzvD0OvF\n7P28yNAwu9AkjVFQdhxT5ufh/2Zs8nwg6lwKWw8cxeXPLUb/ybNRfNT7F0JjP+KTv9iAZ326TwZq\ntDXy7a0SKJ0w4c0VYbm9PdbDBvhed6N3l3n3QIpVWettjhIaCW3SndVBA6Z0AKSmNEP7Vs3RsXUL\ny2PYaSce3r8zAGDQSYkzgY+ZJhPwSyoaambjDSP9HTleg0e/2uSXG/at0dYGeJN/sGIP/veTdXj7\nxwKv9eXHay3Hzjce36oC4XvW9YVHvFJBZkHudkPD7ASThspKbTCzEkP56uuVZRqpscFlY9FRTJmf\nh+KjVThyvAYFBys9fcWtKozVPj1CjGPCG60sOIxXTAYLcyqc+Wm7dwKH4kRtvV/X0WipCPNgeE60\nSYt+0sFODf+awSch9+FLMayv/XRxPGoyKZ1zHzfPvT719TZ8sGIPzjypPa4f1ssTfH0DfKCA939a\n4+rBY9X464yNaJ2Win6dW3v6X+vpoyV5B/HIV5uQ84dRSEtNsf0zcdXuw16PK6vNGy2d/OjUg1qd\nq+HrotblsjzGjLVFuPHcPg0fuBB/5g7/53ykpTbzCuTvLAucyvLt3fPOst0YHCCPv7248QF2Q2H4\nuuRe+ux3YTuWmVe/a/wXXLybMDLT66a7cAV8Z4229vbrYmjjSlQJH/DX7j2C1T5BE3BPttGvS2tP\nn+IHPlmH9YVHsKPUHTR8Uwm+vWAys3Nw4SkZXpNxWOXg/zpjI3YerETR4RPon9EGf9AaQ/XnBqLf\nsQkAj83ajKmGYXWNMfe3hsnEg9Ffm/FLrN6lvH4Z+HosZwsey9mCLX8fg5YtUrA0hNEedb61diub\nTSYH2VgUufsk7n53VcSOTY2n38zXWE5+yBnnIbj34gH47+JdId/JHO8SPqVz7UtL8fdZm/3WX/zM\nIhyqrPG6WWb6j7uxNL8MgP9Pe+NMQTpjW0DQ94+hMThUU03GUA+l/Ux/sxobAe3O3jT0H/Ow9cBR\nfB3gvoFwM3vNydOElhgevDL0yWqmjc+y3O476Uu4atFOfqAa9/3zFadh6z/GhKUM8SjhA76VY1V1\nAQcU8/0Gf8LQe8K38REIHHifmbsN+wwDcYWzg0NVrctylMZA9PHhq2oberzYzdGfqK3HmP987/ic\n4ZREnSYSwm3nZdret0f7dK+U3OjTu3mW7dxU9a/rz/Z6PO6ck2yf2ygt1X5oS6b3W8KndKxY9erw\nvdPWaIo2doudY724MB+5uw95Hr+7bLen0TRW7v94nd86sxuO4lWgBnSKjUDz55qZ9ftR6NwmDZnZ\nOX7bFv/lYpRUVHmNZHrLiD5Yu/ewZ2TU1mmp+Piu8/CL134EAHRsZd3DxlfrFimorKm31Z//pnP7\n4CeZHf06cDTlL4AmHfB98/JGwWYG8vXad4EHlKqrV54fpm/9UODouNFyk2H6PSInnAT8Vi38Q8rL\ntwxF59Yt0L19Orq3T/faltE2DZ/fMxJvLt2FR7/ajHYtU3Guz02GPTu0tDWc9cd3nYfqunrcOm2F\n3x27r906DG3TU72moXziurMA+P/6bcr98hM6pWM24qBRVW10arXFFVXYURq92/NDYffOXEp8nYL0\nOw8m2ydnn9JM8PBVp9t6rtnQCGPP6uHpxw4AJxmCvp7mmTCyHwqevMq0Zv7lvSNtnfvcfp08KUzf\n41xxRnecP6CLybOSq80ooQP+CYsBu4DQxwx3ymwgrEBaOMgtUuy9cbt1o6OuV8eWIR1/1u9HhfQ8\nK2Y18o6tmuPxn51p6/m3n5/pt87ucCV2ascDu7UF4M7Xpze3Tr2IuH8FnKo9R3f3hQNM99e7+QbL\n4f8iq5fXOZJFQqd0gtXg347D9EqrFikxHX6WgmueIp52BLMUhZlQG+vbOryz1I5OrVr4/aK78qwe\nOMUnaAaS3jwF7985HDdPbUh/2JntLO/xKz3L395/AQLVt/RjdfNJ75jRx1Yynt936JQrzuiG/xns\nbtw9/+QuOKd3B0wK0rPoXzcM9izrX1KXDeoWaPcmI6Grm1ZD8gLAl0Em5oiFa8/pGesieJl4QeOH\nl/V1l8Uxx57V3W/dHy452dHxl08ejW/vvwB3juqH3140IODNOsseHO3ouLpbhvf1LJsFSd8B3nL+\nMAotDWPA3HORee3zobH+aRGnYxjdMryP1+P//PIcv3188+SAO01j/HK5YVgvr+1b/u7dFfH8k73T\nH8FuiPrk7vPQ3NAL5+SubXFqd/MvmF4dWwEAOrRsbnlMABinfV6sxvd57dYsXH32SZ5yfnnvSNtf\nbroVk0fjxZuHOHpOImrSAb8xjIM4dWnTuJwoAPzp0lNQ8ORVMRkfxerD2rND8FSEb162b+dWGNi1\njd9+Xdu6+1DrHz5fY8/qjpdvGYbenbzP+afLTvEsX6PV1E7p5j7+dUO8vyB/kdUL3dql4+SubfHw\n1YMwacxp2PDI5bjiDP/amVngC+TWEX3xx0sH4s9XnIo7RvXzrDfLh/v+QuvRviVeuKkhWNQrhVm/\nH+U3wmnH1i1w3+iBuF97vef07oB26cGDntHDV3kP8nepSa20p096acpNQ9AuvTlaNXe/D3p2aIkR\nhpw6AK8vLDMDu7XFtPFZ+PfPB2PBAxdi5u9GYsMjl3u2Oxmh9m//Mwj/vS0r4B3VAPD5PedjyaSL\nPY+fvO5sDOnTAdsfuzLgcxqja7t0v7z/BadkRORcsZTQKZ15W9x91O8bPRDPz8/DlJuGeO5wvWFY\nL3y6qhB3XdjftIfN4F7tsc5wm/3gXu0x43ejkJmdg6vO6oEnrj8LO0srsWlfOW4Z3hdT5ud59c+/\n6dw+aNcy1bL3DuD+adu1Xbrng72/vCHfP/LkzthQWO431dy7dwzHoeM1qKyuQ9e2abhjeq7fcef+\n8QK8sCAPv/lpf4zzmZ8VcOeef/1WLi46NQOHK2s8r3Vonw5YvecIurVLw60j+nq+NAf1aIe7LuyP\nHaWVGHtWd6+++I9fexYe+KShq2eKCL68dyR+9/5qLNzW0L118tjTMbh3B/Tr0hrP/XIwWrdIxbC+\nHbG/vApn9mzv2W/eny7ErdOWY2WB+w5pEUHOH0Yht+AwbjuvLx64/BTMWLsPz87bjpEnd8Hna4pw\n6eldccOw3hhzpv8vBBHBCzcNxeM5m/HLn/TB2CkNZf/pwC743uSu4UljTsOMtUWorXfh8jO647cX\nDfAKvs/feA4ytC+wx649Ew9/2TB/wc3D++DhLzfii3vOx3fbS9GxVXN0at0COX8YhaumLMFlp3fD\nmT3b4907h3vNpTsgo7WnZv3zrF7o2KoF0punYGn2JXh/+W7PYH5mPr37PJzUoaVXYP4h+xK0SUtF\np9YtcKiyBi/ePAS/e38NfjW8L95f3jAQWystT96lrfvLa+IF/b2+jFY85P4l9Pavz/WbZMb4A8TY\np74x0punBE2fDO3T0evxuf064Yt77DXeWnn5lqG2hm9YPnk02tv4BZJwlDaxRCz/DRs2TIXi9e92\nqL6TZqllOw561vWdNEv1nTRLKaVUfb1LKaXUil1lqu+kWepXU5epnPX71G3TliullHpxQZ5n/4Vb\niy3PVVNXr95dVqBOe3iO6jtplvpyTaFSSqncgjKVV1yhrnt5qcr+bL2aubbIc14zU77drvpOmqXy\nSyqUUkrtPVSplu8sU8er69QL87ertXsO+z3nSGWNWrClWOUWuF9H/wdzvLZ/vnqvOv+J+Sq3oEyN\nfX6xyiuu8Nq+fu8Rdf3LS9Xx6jpVdqxaLdpW4tlWXH5CXfbsIrWnrNLy9f9txkb10sI8Ne7FJepH\n7XrX1tWr67XX/dmqvcrlCvy6fR2vrlPXvPC9Wr37kOn22rp6NWvdPkfH1G0oPKLyio96HlfV1qnZ\n6/ep/UdOqKX5pY6Pp5RSD3+xQQ1+dK56ZOZGpZSyXa5/fb1F/XP2ZjVv0wFb+z//7Xb1eM5mddfb\nuV7vZSPf13eg/ITn/4lergc+Xqum/7DL8hrmFR9VG4uOBCzLyl1lau8h6/fFr6YuU1+tKwr6uigy\nAOQqB7FWVATGvhaRMQCeB5ACYKpS6kmr/bOyslRurn8t1o78kmMYkNHa0/ByuLIGzUTQvpX3t3PB\nwUr07dzKtBeBPu6OXQUHK5HpYH+jepdC0eET6NO5VUjPn/r9Towa2AWndU/sYVopuMrqOvevvHb2\nU1OUXERklVLKXlcyIPwBX0RSAGwHcBmAQgArAdyklPIf8EbTmIBPRJSsnAb8SDTangsgXym1UylV\nA+BDAOMicB4iInIgEgG/JwDjRJKF2jovIjJRRHJFJLe0NPC4NkREFB4x65aplHpdKZWllMrKyGh6\n3Z+IiOJNJAJ+EYDehse9tHVERBRDkQj4KwEMFJF+ItICwI0AZkbgPERE5EDYb7xSStWJyO8AzIW7\nW+YbSqlN4T4PERE5E5E7bZVSswHMjsSxiYgoNAk9lg4REdkXkTttHRdCpBTA7hCf3gWA/2Ap8Y1l\njrxEKy+QeGVOtPICTa/MfZVStrs5xkXAbwwRyXVyp1k8YJkjL9HKCyRemROtvADLzJQOEVGSYMAn\nIkoSTSHgvx7rAoSAZY68RCsvkHhlTrTyAkle5oTP4RMRkT1NoYZPREQ2MOATESWJhA74IjJGRLaJ\nSL6IZMe6PAAgIr1FZKGIbBaRTSJyn7a+k4jME5E87W9Hbb2IyBTtNawXkaExLHuKiKwRkVna434i\nslwr20fa2EgQkTTtcb62PTMGZe0gIp+KyFYR2SIi58X7NRaRP2nviY0i8oGIpMfbNRaRN0SkREQ2\nGtY5vq4iMl7bP09ExsegzE9r7431IvKFiHQwbHtQK/M2EbnCsD4q8cSsvIZtD4iIEpEu2uPwXmMn\n8yHG0z+4x+nZAaA/gBYA1gEYFAfl6gFgqLbcFu7ZvwYB+BeAbG19NoCntOWxAOYAEAAjACyPYdnv\nB/A+gFna448B3Kgtvwrgt9ryPQBe1ZZvBPBRDMo6HcCd2nILAB3i+RrDPSfELgAtDdf29ni7xgAu\nADAUwEbDOkfXFUAnADu1vx215Y5RLvPlAFK15acMZR6kxYo0AP20GJISzXhiVl5tfW+4xyDbDaBL\nJK5xVN/0Yb5o5wGYa3j8IIAHY10uk3LOgHu6x20AemjregDYpi2/BvcUkPr+nv2iXM5eAOYDuATA\nLO0NdtDwofFcb+1NeZ62nKrtJ1Esa3steIrP+ri9xmiYGKiTds1mAbgiHq8xgEyf4OnougK4CcBr\nhvVe+0WjzD7bfgbgPW3ZK07o1zna8cSsvAA+BTAYQAEaAn5Yr3Eip3RszawVS9rP8CEAlgPoppTa\nr206AKCbthwvr+M/AP4CwKU97gzgiFKqzqRcnjJr28u1/aOlH4BSAG9qKaipItIacXyNlVJFAJ4B\nsAfAfriv2SrE7zU2cnpdY369ffwa7loyEKdlFpFxAIqUUut8NoW1vIkc8OOaiLQB8BmAPyqljhq3\nKfdXctz0hxWRqwGUKKVWxbosNqXC/ZP4FaXUEACVcKcaPOLwGneEe27nfgBOAtAawJiYFioE8XZd\ngxGRhwDUAXgv1mUJRERaAZgM4K+RPlciB/y4nVlLRJrDHezfU0p9rq0uFpEe2vYeAEq09fHwOkYC\nuEZECuCedP4SAM8D6CAi+hDaxnJ5yqxtbw+gLIrlLQRQqJRarj3+FO4vgHi+xpcC2KWUKlVK1QL4\nHO7rHq/X2MjpdY2H6w0RuR3A1QBu0b6ogPgs8wC4KwLrtM9gLwCrRaS7RblCKm8iB/y4nFlLRATA\nNABblFLPGjbNBKC3pI+HO7evr79Na40fAaDc8PM5KpRSDyqleimlMuG+jguUUrcAWAjghgBl1l/L\nDdr+Uav1KaUOANgrIqdqq0YD2Iw4vsZwp3JGiEgr7T2ilzkur7EPp9d1LoDLRaSj9svmcm1d1IjI\nGLhTlNcopY4bNs0EcKPWC6ofgIEAViCG8UQptUEp1VUplal9Bgvh7vhxAOG+xpFsSIn0P7hbsLfD\n3br+UKzLo5VpFNw/edcDWKv9Gwt3/nU+gDwA3wLopO0vAF7SXsMGAFkxLv9FaOil0x/uD0M+gE8A\npGnr07XH+dr2/jEo5zkAcrXr/CXcPRXi+hoDeBTAVgAbAbwDd0+RuLrGAD6Au42hVgs8d4RyXeHO\nm+dr/ybEoMz5cOe49c/gq4b9H9LKvA3AlYb1UYknZuX12V6AhkbbsF5jDq1ARJQkEjmlQ0REDjDg\nExElCQZ8IqIkwYBPRJQkGPCJiJIEAz4RUZJgwCciShL/D20pUmumtCntAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(episode_length_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "KF1UKCM3rp4m",
    "outputId": "8bf2f377-4b42-4768-cedd-942434f7bebc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./weights/DQN_model.ckpt\n",
      "0 500\n",
      "1 500\n",
      "2 500\n",
      "3 500\n",
      "4 500\n",
      "5 500\n",
      "6 500\n",
      "7 500\n",
      "8 500\n",
      "9 500\n",
      "10 500\n",
      "11 500\n",
      "12 500\n",
      "13 500\n",
      "14 500\n",
      "15 500\n",
      "16 500\n",
      "17 500\n",
      "18 500\n",
      "19 500\n",
      "20 500\n",
      "21 500\n",
      "22 500\n",
      "23 500\n",
      "24 500\n",
      "25 500\n",
      "26 500\n",
      "27 500\n",
      "28 500\n",
      "29 500\n",
      "30 500\n",
      "31 500\n",
      "32 500\n",
      "33 500\n",
      "34 500\n",
      "35 500\n",
      "36 500\n",
      "37 500\n",
      "38 500\n",
      "39 500\n",
      "40 500\n",
      "41 500\n",
      "42 500\n",
      "43 500\n",
      "44 500\n",
      "45 500\n",
      "46 500\n",
      "47 500\n",
      "48 500\n",
      "49 500\n",
      "50 500\n",
      "51 500\n",
      "52 500\n",
      "53 500\n",
      "54 500\n",
      "55 500\n",
      "56 500\n",
      "57 500\n",
      "58 500\n",
      "59 500\n",
      "60 500\n",
      "61 500\n",
      "62 500\n",
      "63 500\n",
      "64 500\n",
      "65 500\n",
      "66 500\n",
      "67 500\n",
      "68 500\n",
      "69 500\n",
      "70 500\n",
      "71 500\n",
      "72 500\n",
      "73 500\n",
      "74 500\n",
      "75 500\n",
      "76 500\n",
      "77 500\n",
      "78 500\n",
      "79 500\n",
      "80 500\n",
      "81 500\n",
      "82 500\n",
      "83 500\n",
      "84 500\n",
      "85 500\n",
      "86 500\n",
      "87 500\n",
      "88 500\n",
      "89 500\n",
      "90 500\n",
      "91 500\n",
      "92 500\n",
      "93 500\n",
      "94 500\n",
      "95 500\n",
      "96 500\n",
      "97 500\n",
      "98 500\n",
      "99 500\n"
     ]
    }
   ],
   "source": [
    "# test our network\n",
    "tf.reset_default_graph()\n",
    "RL = DQN(actions_num = 2, gamma = 1,\n",
    "         state_size = 4, epsilon_start = 1,\n",
    "         learning_rate = 1e-3, epsilon_min = 0,\n",
    "         replace_target_iter = 100, memory_size = 5000,\n",
    "         epsilon_increment = None,)\n",
    "# load saved parameters\n",
    "RL.restore()\n",
    "# run 100 trails and print how long can the agent hold the cart pole for each trail\n",
    "for i in range(100):\n",
    "  ############################\n",
    "  # YOUR CODE STARTS HERE\n",
    "    done=False\n",
    "    hold =0\n",
    "    new_state = env.reset()\n",
    "    while not done:\n",
    "        hold += 1\n",
    "        action = RL.choose_action(new_state)\n",
    "        state_next, reward, done, info = env.step(action)  \n",
    "        new_state = state_next\n",
    "    print(i,hold)\n",
    "  # YOUR CODE ENDS HERE\n",
    "  ############################\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gxhwfe303YhK"
   },
   "source": [
    "You may find that the episode length doesn't stably improve as more training time is given. You can read chapter 3.2 of this paper https://arxiv.org/pdf/1711.07478.pdf if you are interested."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ELEN_6885_HW4_Part_4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
